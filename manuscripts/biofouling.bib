
@MANUAL{Hayes2007-mm,
  title        = "{Empirical validation: Small vessel translocation of key
                  threatening species}",
  author       = "Hayes, Keith R and Gunasekera, Rasanthi and Patil, Jawahar
                  and Sliwa, Cath and Migus, Sasha and McEnnulty, Felicity and
                  Dunstan, Piers and Green, Mark and Sutton, Caroline",
  number       = "Australian Government Natural Heritage Trust Project 46630",
  month        =  feb,
  year         =  2007,
  organization = "CSIRO",
  isbn         = "9781921232534"
}

@ARTICLE{Willan2000-yy,
  title     = "{Outbreak of Mytilopsis sallei (R{\'e}cluz, 1849) (Bivalvia:
               Dreissenidae) in Australia}",
  author    = "Willan, Richard C and Russell, Barry C and Murfet, Nicolas B and
               Moore, Kirrily L and McEnnulty, Felicity R and Horner, Suzanne K
               and Hewitt, Chad L and Dally, Gavin M and Campbell, Marnie L and
               Bourke, Sean T",
  journal   = "Molluscan research",
  publisher = "Taylor \& Francis",
  volume    =  20,
  number    =  2,
  pages     = "25--30",
  month     =  jan,
  year      =  2000,
  url       = "http://dx.doi.org/10.1080/13235818.2000.10673730",
  issn      = "1323-5818",
  doi       = "10.1080/13235818.2000.10673730"
}

@MANUAL{International_Maritime_Organization2011-vc,
  title  = "{Guidelines for the control and management of ships' biofouling to
            minimize the transfer of invasive aquatic species}",
  author = "{International Maritime Organization}",
  number = "MEPC.207(62)",
  month  =  jul,
  year   =  2011
}

@ARTICLE{Drake2007-uf,
  title   = "{Hull fouling is a risk factor for intercontinental species
             exchange in aquatic ecosystems}",
  author  = "Drake, John",
  journal = "Aquatic Invasions",
  volume  =  2,
  number  =  2,
  pages   = "121--131",
  year    =  2007,
  url     = "http://www.aquaticinvasions.net/2007/index2.html",
  issn    = "1818-5487",
  doi     = "10.3391/ai.2007.2.2.7"
}

@ARTICLE{Molnar2008-bn,
  title     = "{Assessing the global threat of invasive species to marine
               biodiversity}",
  author    = "Molnar, Jennifer L and Gamboa, Rebecca L and Revenga, Carmen and
               Spalding, Mark D",
  abstract  = "Although invasive species are widely recognized as a major
               threat to marine biodiversity, there has been no quantitative
               global assessment of their impacts and routes of introduction.
               Here, we report initial results from the first such global
               assessment. Drawing from over 350 databases and other sources,
               we synthesized information on 329 marine invasive species,
               including their distribution, impacts on biodiversity, and
               introduction pathways. Initial analyses show that only 16\% of
               marine ecoregions have no reported marine invasions, and even
               that figure may be inflated due to under-reporting.
               International shipping, followed by aquaculture, represent the
               major means of introduction. Our geographically referenced and
               publicly available database provides a framework that can be
               used to highlight the invasive taxa that are most threatening,
               as well as to prioritize the invasion pathways that pose the
               greatest threat.",
  journal   = "Frontiers in ecology and the environment",
  publisher = "Ecological Society of America",
  volume    =  6,
  number    =  9,
  pages     = "485--492",
  month     =  "1~" # nov,
  year      =  2008,
  url       = "http://dx.doi.org/10.1890/070064",
  issn      = "1540-9295, 1540-9309",
  doi       = "10.1890/070064"
}

@BOOK{Gelman2007-lc,
  title     = "{Data Analysis Using Regression and Multilevel/Hierarchical
               Models}",
  author    = "Gelman, Andrew and Hill, Jennifer",
  abstract  = "Data Analysis Using Regression and Multilevel/Hierarchical
               Models is a comprehensive manual for the applied researcher who
               wants to perform data analysis using linear and nonlinear
               regression and multilevel models. The book introduces a wide
               variety of models, whilst at the same time instructing the
               reader in how to fit these models using available software
               packages. The book illustrates the concepts by working through
               scores of real data examples that have arisen from the authors'
               own applied research, with programming codes provided for each
               one. Topics covered include causal inference, including
               regression, poststratification, matching, regression
               discontinuity, and instrumental variables, as well as multilevel
               logistic regression and missing-data imputation. Practical tips
               regarding building, fitting, and understanding are provided
               throughout. Author resource page:
               http://www.stat.columbia.edu/~gelman/arm/",
  publisher = "Cambridge University Press",
  year      =  2007,
  language  = "en",
  isbn      = "9780521867061"
}

@ARTICLE{Zhou2010-pc,
  title    = "{A Note on Bayesian Inference After Multiple Imputation}",
  author   = "Zhou, Xiang and Reiter, Jerome P",
  abstract = "This article is aimed at practitioners who plan to use Bayesian
              inference on multiply-imputed datasets in settings where
              posterior distributions of the parameters of interest are not
              approximately Gaussian. We seek to steer practitioners away from
              a naive approach to Bayesian inference, namely estimating the
              posterior distribution in each completed dataset and averaging
              functionals of these distributions. We demonstrate that this
              approach results in unreliable inferences. A better approach is
              to mix draws from the posterior distributions from each completed
              dataset, and use the mixed draws to summarize the posterior
              distribution. Using simulations, we show that for this second
              approach to work well, the number of imputed datasets should be
              large. In particular, five to ten imputed datasets---which is the
              standard recommendation for multiple imputation---is generally
              not enough to result in reliable Bayesian inferences.",
  journal  = "The American statistician",
  volume   =  64,
  number   =  2,
  pages    = "159--163",
  year     =  2010,
  url      = "http://dx.doi.org/10.1198/tast.2010.09109",
  eprint   = "http://dx.doi.org/10.1198/tast.2010.09109",
  issn     = "0003-1305",
  doi      = "10.1198/tast.2010.09109"
}

@ARTICLE{Stekhoven2012-bx,
  title       = "{MissForest--non-parametric missing value imputation for
                 mixed-type data}",
  author      = "Stekhoven, Daniel J and B{\"u}hlmann, Peter",
  affiliation = "Seminar for Statistics, Department of Mathematics, ETH Zurich,
                 Zurich, Switzerland.",
  abstract    = "MOTIVATION: Modern data acquisition based on high-throughput
                 technology is often facing the problem of missing data.
                 Algorithms commonly used in the analysis of such large-scale
                 data often depend on a complete set. Missing value imputation
                 offers a solution to this problem. However, the majority of
                 available imputation methods are restricted to one type of
                 variable only: continuous or categorical. For mixed-type data,
                 the different types are usually handled separately. Therefore,
                 these methods ignore possible relations between variable
                 types. We propose a non-parametric method which can cope with
                 different types of variables simultaneously. RESULTS: We
                 compare several state of the art methods for the imputation of
                 missing values. We propose and evaluate an iterative
                 imputation method (missForest) based on a random forest. By
                 averaging over many unpruned classification or regression
                 trees, random forest intrinsically constitutes a multiple
                 imputation scheme. Using the built-in out-of-bag error
                 estimates of random forest, we are able to estimate the
                 imputation error without the need of a test set. Evaluation is
                 performed on multiple datasets coming from a diverse selection
                 of biological fields with artificially introduced missing
                 values ranging from 10\% to 30\%. We show that missForest can
                 successfully handle missing values, particularly in datasets
                 including different types of variables. In our comparative
                 study, missForest outperforms other methods of imputation
                 especially in data settings where complex interactions and
                 non-linear relations are suspected. The out-of-bag imputation
                 error estimates of missForest prove to be adequate in all
                 settings. Additionally, missForest exhibits attractive
                 computational efficiency and can cope with high-dimensional
                 data. AVAILABILITY: The package missForest is freely available
                 from http://stat.ethz.ch/CRAN/. CONTACT:
                 stekhoven@stat.math.ethz.ch; buhlmann@stat.math.ethz.ch",
  journal     = "Bioinformatics",
  volume      =  28,
  number      =  1,
  pages       = "112--118",
  month       =  "1~" # jan,
  year        =  2012,
  url         = "http://dx.doi.org/10.1093/bioinformatics/btr597",
  language    = "en",
  issn        = "1367-4803, 1367-4811",
  pmid        = "22039212",
  doi         = "10.1093/bioinformatics/btr597"
}

@ARTICLE{Lubin2004-qe,
  title       = "{Epidemiologic evaluation of measurement data in the presence
                 of detection limits}",
  author      = "Lubin, Jay H and Colt, Joanne S and Camann, David and Davis,
                 Scott and Cerhan, James R and Severson, Richard K and
                 Bernstein, Leslie and Hartge, Patricia",
  affiliation = "Division of Cancer Epidemiology and Genetics, National Cancer
                 Institute, Bethesda, Maryland, USA. lubinj@mail.nih.gov",
  abstract    = "Quantitative measurements of environmental factors greatly
                 improve the quality of epidemiologic studies but can pose
                 challenges because of the presence of upper or lower detection
                 limits or interfering compounds, which do not allow for
                 precise measured values. We consider the regression of an
                 environmental measurement (dependent variable) on several
                 covariates (independent variables). Various strategies are
                 commonly employed to impute values for interval-measured data,
                 including assignment of one-half the detection limit to
                 nondetected values or of ``fill-in'' values randomly selected
                 from an appropriate distribution. On the basis of a limited
                 simulation study, we found that the former approach can be
                 biased unless the percentage of measurements below detection
                 limits is small (5-10\%). The fill-in approach generally
                 produces unbiased parameter estimates but may produce biased
                 variance estimates and thereby distort inference when 30\% or
                 more of the data are below detection limits. Truncated data
                 methods (e.g., Tobit regression) and multiple imputation offer
                 two unbiased approaches for analyzing measurement data with
                 detection limits. If interest resides solely on regression
                 parameters, then Tobit regression can be used. If
                 individualized values for measurements below detection limits
                 are needed for additional analysis, such as relative risk
                 regression or graphical display, then multiple imputation
                 produces unbiased estimates and nominal confidence intervals
                 unless the proportion of missing data is extreme. We
                 illustrate various approaches using measurements of pesticide
                 residues in carpet dust in control subjects from a
                 case-control study of non-Hodgkin lymphoma.",
  journal     = "Environmental health perspectives",
  volume      =  112,
  number      =  17,
  pages       = "1691--1696",
  month       =  dec,
  year        =  2004,
  url         = "https://www.ncbi.nlm.nih.gov/pubmed/15579415",
  language    = "en",
  issn        = "0091-6765",
  pmid        = "15579415",
  pmc         = "PMC1253661"
}

@ARTICLE{Burton2007-ft,
  title       = "{Cost-effectiveness in clinical trials: using multiple
                 imputation to deal with incomplete cost data}",
  author      = "Burton, Andrea and Billingham, Lucinda Jane and Bryan,
                 Stirling",
  affiliation = "Cancer Research UK Clinical Trials Unit, University of
                 Birmingham, Birmingham, UK. andrea.burton@warwick.ac.uk.",
  abstract    = "BACKGROUND: Cost-effectiveness has become an important outcome
                 in many clinical trials and has resulted in the collection of
                 resource use data and the calculation of costs for individual
                 patients. A specific example is a Cancer Research UK phase III
                 trial comparing chemotherapy (CT) against standard palliative
                 care in patients with advanced non-small cell lung cancer.
                 Resource usage from trial entry until death were collected and
                 costs obtained on a subset of 115 trial patients. For some
                 patients, however, the unavailability of medical notes
                 resulted in some cost components, and hence total cost, being
                 missing. The 82 patients with complete data were not
                 representative of all trial patients in terms of effectiveness
                 and thus it was necessary to address the missing data problem.
                 METHODS: Multiple imputation (MI) was used to impute values
                 for the unobserved individual cost components, allowing total
                 cost to be calculated and cost-effectiveness carried out for
                 all patients in the cost sub-study. The results are compared
                 with those from a complete case analysis. RESULTS: After MI,
                 the results indicated that CT had a high probability of being
                 cost-effective for a societal willingness to pay over 20,000
                 Pounds per life-year gained. This was in stark contrast with
                 the complete case analysis, which suggested that CT was not a
                 cost-effective use of resources at any reasonable level of
                 willingness to pay for a life-year. LIMITATIONS: Our findings
                 are based on a relatively small retrospective study with all
                 events observed. CONCLUSION: In conclusion, cost-effectiveness
                 analysis of the complete cases only may give biased results,
                 and therefore, in situations where there are missing costs, MI
                 is recommended.",
  journal     = "Clinical trials",
  volume      =  4,
  number      =  2,
  pages       = "154--161",
  year        =  2007,
  url         = "http://dx.doi.org/10.1177/1740774507076914",
  language    = "en",
  issn        = "1740-7745",
  pmid        = "17456514",
  doi         = "10.1177/1740774507076914"
}

@ARTICLE{White2009-yn,
  title       = "{Imputing missing covariate values for the Cox model}",
  author      = "White, Ian R and Royston, Patrick",
  affiliation = "MRC Biostatistics Unit, Institute of Public Health, Robinson
                 Way, Cambridge CB2 0SR, UK. ian.white@mrc-bsu.cam.ac.uk",
  abstract    = "Multiple imputation is commonly used to impute missing data,
                 and is typically more efficient than complete cases analysis
                 in regression analysis when covariates have missing values.
                 Imputation may be performed using a regression model for the
                 incomplete covariates on other covariates and, importantly, on
                 the outcome. With a survival outcome, it is a common practice
                 to use the event indicator D and the log of the observed event
                 or censoring time T in the imputation model, but the rationale
                 is not clear.We assume that the survival outcome follows a
                 proportional hazards model given covariates X and Z. We show
                 that a suitable model for imputing binary or Normal X is a
                 logistic or linear regression on the event indicator D, the
                 cumulative baseline hazard H(0)(T), and the other covariates
                 Z. This result is exact in the case of a single binary
                 covariate; in other cases, it is approximately valid for small
                 covariate effects and/or small cumulative incidence. If we do
                 not know H(0)(T), we approximate it by the Nelson-Aalen
                 estimator of H(T) or estimate it by Cox regression.We compare
                 the methods using simulation studies. We find that using logT
                 biases covariate-outcome associations towards the null, while
                 the new methods have lower bias. Overall, we recommend
                 including the event indicator and the Nelson-Aalen estimator
                 of H(T) in the imputation model.",
  journal     = "Statistics in medicine",
  volume      =  28,
  number      =  15,
  pages       = "1982--1998",
  month       =  "10~" # jul,
  year        =  2009,
  url         = "http://dx.doi.org/10.1002/sim.3618",
  language    = "en",
  issn        = "0277-6715, 1097-0258",
  pmid        = "19452569",
  doi         = "10.1002/sim.3618",
  pmc         = "PMC2998703"
}

@ARTICLE{Meng1992-yh,
  title     = "{Performing Likelihood Ratio Tests with Multiply-Imputed Data
               Sets}",
  author    = "Meng, Xiao-Li and Rubin, Donald B",
  abstract  = "Existing procedures for obtaining significance levels from
               multiply-imputed data either (i) require access to the
               complete-data point estimates and variance-covariance matrices,
               which may not be available in practice when the dimensionality
               of the estimand is high, or (ii) directly combine p-values with
               less satisfactory results. Taking advantage of the well-known
               relationship between the Wald and log likelihood ratio test
               statistics, we propose a complete-data log likelihood ratio
               based procedure. It is shown that, for any number of multiple
               imputations, the proposed procedure is equivalent in large
               samples to the existing procedure based on the point estimates
               and the variance-covariance matrices, yet it only requires the
               point estimates and evaluations of the complete-data log
               likelihood ratio statistic as a function of these estimates and
               the completed data. The proposed procedure, therefore, is
               especially attractive with highly multiparameter incomplete-data
               problems since it does not involve the computation of any
               matrices.",
  journal   = "Biometrika",
  publisher = "[Oxford University Press, Biometrika Trust]",
  volume    =  79,
  number    =  1,
  pages     = "103--111",
  year      =  1992,
  url       = "http://www.jstor.org/stable/2337151",
  issn      = "0006-3444",
  doi       = "10.2307/2337151"
}

@MANUAL{Stan_Development_Team2016-xb,
  title  = "{Stan Modeling Language Users Guide and Reference Manual}",
  author = "{Stan Development Team}",
  year   =  2016,
  url    = "http://mc-stan.org/"
}

@ARTICLE{Vehtari2016-dp,
  title     = "{Practical Bayesian model evaluation using leave-one-out
               cross-validation and WAIC}",
  author    = "Vehtari, Aki and Gelman, Andrew and Gabry, Jonah",
  abstract  = "Leave-one-out cross-validation (LOO) and the widely applicable
               information criterion (WAIC) are methods for estimating
               pointwise out-of-sample prediction accuracy from a fitted
               Bayesian model using th",
  journal   = "Statistics and computing",
  publisher = "Springer US",
  pages     = "1--20",
  month     =  aug,
  year      =  2016,
  url       = "http://link.springer.com/article/10.1007/s11222-016-9696-4",
  language  = "en",
  issn      = "0960-3174, 1573-1375",
  doi       = "10.1007/s11222-016-9696-4"
}

@BOOK{Pimentel2011-pe,
  title     = "{Biological Invasions: Economic and Environmental Costs of Alien
               Plant, Animal, and Microbe Species}",
  author    = "Pimentel, David",
  abstract  = "The impact of invasive species is second only to that of human
               population growth and associated activities as a cause of the
               loss of biodiversity throughout the world. In the United States,
               invasions of nonnative plants, animals, or microbes cause major
               environmental damage. The second edition of Biological
               Invasions: Economic and Environmental Costs of Alien Plant,
               Animal, and Microbe Species represents the most current,
               single-source reference containing scientific and economic
               information on this timely subject. This volume reconfirms the
               diverse and unpredictable roles that non-native species assume
               as they invade new ecosystems: destruction of vital crops and
               forests, major damages to ecosystems leading to loss of
               biodiversity, soil erosion, and water loss. The text provides
               information on how the non-native species invade new ecosystems,
               their subsequent environmental effects, and estimates on
               economic impacts. Biological Invasions supplies scientists,
               policymakers, and the public with a better understanding of the
               invading species and how to prevent their spread and improve
               control procedures.",
  publisher = "Hoboken: CRC Press, 2011.",
  edition   = "Second",
  year      =  2011,
  keywords  = "Electronic books; Biological invasions -- Economic aspects;
               Biological invasions -- Environmental aspects; Biological
               invasions"
}

@ARTICLE{Erler2016-gi,
  title    = "{Dealing with missing covariates in epidemiologic studies: a
              comparison between multiple imputation and a full Bayesian
              approach}",
  author   = "Erler, Nicole S and Rizopoulos, Dimitris and Rosmalen, Joost van
              and Jaddoe, Vincent W V and Franco, Oscar H and Lesaffre,
              Emmanuel M E H",
  abstract = "Incomplete data are generally a challenge to the analysis of most
              large studies. The current gold standard to account for missing
              data is multiple imputation, and more specifically multiple
              imputation with chained equations (MICE). Numerous studies have
              been conducted to illustrate the performance of MICE for missing
              covariate data. The results show that the method works well in
              various situations. However, less is known about its performance
              in more complex models, specifically when the outcome is
              multivariate as in longitudinal studies. In current practice, the
              multivariate nature of the longitudinal outcome is often
              neglected in the imputation procedure, or only the baseline
              outcome is used to impute missing covariates. In this work, we
              evaluate the performance of MICE using different strategies to
              include a longitudinal outcome into the imputation models and
              compare it with a fully Bayesian approach that jointly imputes
              missing values and estimates the parameters of the longitudinal
              model. Results from simulation and a real data example show that
              MICE requires the analyst to correctly specify which components
              of the longitudinal process need to be included in the imputation
              models in order to obtain unbiased results. The full Bayesian
              approach, on the other hand, does not require the analyst to
              explicitly specify how the longitudinal outcome enters the
              imputation models. It performed well under different scenarios.
              Copyright \copyright{} 2016 John Wiley \& Sons, Ltd.",
  journal  = "Statistics in medicine",
  month    =  "1~" # jan,
  year     =  2016,
  url      = "http://dx.doi.org/10.1002/sim.6944",
  keywords = "Bayesian; epidemiology; MICE; missing covariate values; multiple
              imputation",
  issn     = "0277-6715, 1097-0258",
  doi      = "10.1002/sim.6944"
}

@ARTICLE{Bondarenko2016-tf,
  title    = "{Graphical and numerical diagnostic tools to assess suitability of
              multiple imputations and imputation models}",
  author   = "Bondarenko, Irina and Raghunathan, Trivellore",
  abstract = "Multiple imputation has become a popular approach for analyzing
              incomplete data. Many software packages are available to multiply
              impute the missing values and to analyze the resulting completed
              data sets. However, diagnostic tools to check the validity of the
              imputations are limited, and the majority of the currently
              available methods need considerable knowledge of the imputation
              model. In many practical settings, however, the imputer and the
              analyst may be different individuals or from different
              organizations, and the analyst model may or may not be congenial
              to the model used by the imputer. This article develops and
              evaluates a set of graphical and numerical diagnostic tools for
              two practical purposes: (i) for an analyst to determine whether
              the imputations are reasonable under his/her model assumptions
              without actually knowing the imputation model assumptions; and
              (ii) for an imputer to fine tune the imputation model by checking
              the key characteristics of the observed and imputed values. The
              tools are based on the numerical and graphical comparisons of the
              distributions of the observed and imputed values conditional on
              the propensity of response. The methodology is illustrated using
              simulated data sets created under a variety of scenarios. The
              examples focus on continuous and binary variables, but the
              principles can be used to extend methods for other types of
              variables. Copyright \copyright{} 2016 John Wiley \& Sons, Ltd.",
  journal  = "Statistics in medicine",
  month    =  "1~" # jan,
  year     =  2016,
  url      = "http://dx.doi.org/10.1002/sim.6926",
  keywords = "multiple imputation; propensity score; diagnostics; congeniality",
  issn     = "0277-6715, 1097-0258",
  doi      = "10.1002/sim.6926"
}

@ARTICLE{Kenward2007-kc,
  title    = "{Multiple imputation: current perspectives}",
  author   = "Kenward, M G and Carpenter, J",
  journal  = "Statistical methods in medical research",
  volume   =  16,
  number   =  3,
  pages    = "199",
  year     =  2007,
  keywords = "JC",
  issn     = "0962-2802"
}

@ARTICLE{Mehrotra2012-wv,
  title    = "{Analysis of Longitudinal Clinical Trials with Missing Data Using
              Multiple Imputation in Conjunction with Robust Regression}",
  author   = "Mehrotra, Devan V and Li, Xiaoming and Liu, Jiajun and Lu,
              Kaifeng",
  abstract = "Summary In a typical randomized clinical trial, a continuous
              variable of interest (e.g., bone density) is measured at baseline
              and fixed postbaseline time points. The resulting longitudinal
              data, often incomplete due to dropouts and other reasons, are
              commonly analyzed using parametric likelihood-based methods that
              assume multivariate normality of the response vector. If the
              normality assumption is deemed untenable, then semiparametric
              methods such as (weighted) generalized estimating equations are
              considered. We propose an alternate approach in which the missing
              data problem is tackled using multiple imputation, and each
              imputed dataset is analyzed using robust regression
              (M-estimation; Huber, 1973, Annals of Statistics1, 799-821.) to
              protect against potential non-normality/outliers in the original
              or imputed dataset. The robust analysis results from each imputed
              dataset are combined for overall estimation and inference using
              either the simple Rubin (1987, Multiple Imputation for
              Nonresponse in Surveys, New York: Wiley) method, or the more
              complex but potentially more accurate Robins and Wang (2000,
              Biometrika87, 113-124.) method. We use simulations to show that
              our proposed approach performs at least as well as the standard
              methods under normality, but is notably better under both
              elliptically symmetric and asymmetric non-normal distributions. A
              clinical trial example is used for illustration.",
  journal  = "Biometrics",
  month    =  "20~" # sep,
  year     =  2012,
  url      = "http://www.ncbi.nlm.nih.gov/pubmed/22994905",
  keywords = "dropouts; longitudinal data; m-estimation; missing data; multiple
              imputation; non-normality; outliers",
  issn     = "0006-341X, 1541-0420",
  pmid     = "22994905",
  doi      = "10.1111/j.1541-0420.2012.01780.x"
}

@ARTICLE{Gelman1992-zo,
  title   = "{Inference from Iterative Simulation Using Multiple Sequences}",
  author  = "Gelman, Andrew and Rubin, Donald B",
  journal = "Statistical science: a review journal of the Institute of
             Mathematical Statistics",
  volume  =  7,
  number  =  4,
  pages   = "457--472",
  year    =  1992,
  issn    = "0883-4237"
}

@ARTICLE{Hu2013-lk,
  title   = "{Are Independent Parameter Draws Necessary for Multiple Imputation?}",
  author  = "Hu, Jingchen and Mitra, Robin and Reiter, Jerome",
  journal = "The American statistician",
  number  = "September",
  pages   = "130712060217009",
  month   =  "12~" # jul,
  year    =  2013,
  url     = "http://www.tandfonline.com/doi/abs/10.1080/00031305.2013.821953",
  issn    = "0003-1305",
  doi     = "10.1080/00031305.2013.821953"
}

@ARTICLE{Van_Buuren2011-ne,
  title    = "{mice: Multivariate Imputation by Chained Equations in R}",
  author   = "van Buuren, Stef and Groothuis-Oudshoorn, Karin",
  journal  = "Journal of statistical software",
  volume   =  45,
  number   =  3,
  pages    = "1--67",
  year     =  2011,
  url      = "http://www.jstatsoft.org/v45/i03",
  keywords = "chained equations; fully conditional specification; gibbs
              sampler; mice; multiple imputation; passive imputation; predictor
              selection; r",
  issn     = "1548-7660"
}

@ARTICLE{Su2011-sz,
  title    = "{Multiple Imputation with Diagnostics (mi) in R: Opening Windows
              into the Black Box}",
  author   = "Su, Yu-Sung and Gelman, Andrew and Hill, Jennifer and Yajima,
              Masanao",
  journal  = "Journal of statistical software",
  volume   =  45,
  number   =  2,
  pages    = "1--31",
  year     =  2011,
  url      = "http://www.jstatsoft.org/v45/i02",
  keywords = "chained equations; model diagnostics; multiple imputation; weakly
              informative",
  issn     = "1548-7660"
}

@ARTICLE{Lee2010-hr,
  title    = "{Multiple imputation for missing data: fully conditional
              specification versus multivariate normal imputation}",
  author   = "Lee, Katherine J and Carlin, John B",
  abstract = "Statistical analysis in epidemiologic studies is often hindered
              by missing data, and multiple imputation is increasingly being
              used to handle this problem. In a simulation study, the authors
              compared 2 methods for imputation that are widely available in
              standard software: fully conditional specification (FCS) or
              ``chained equations'' and multivariate normal imputation (MVNI).
              The authors created data sets of 1,000 observations to simulate a
              cohort study, and missing data were induced under 3 missing-data
              mechanisms. Imputations were performed using FCS (Royston's
              ``ice'') and MVNI (Schafer's NORM) in Stata (Stata Corporation,
              College Station, Texas), with transformations or prediction
              matching being used to manage nonnormality in the continuous
              variables. Inferences for a set of regression parameters were
              compared between these approaches and a complete-case analysis.
              As expected, both FCS and MVNI were generally less biased than
              complete-case analysis, and both produced similar results despite
              the presence of binary and ordinal variables that clearly did not
              follow a normal distribution. Ignoring skewness in a continuous
              covariate led to large biases and poor coverage for the
              corresponding regression parameter under both approaches,
              although inferences for other parameters were largely unaffected.
              These results provide reassurance that similar results can be
              expected from FCS and MVNI in a standard regression analysis
              involving variously scaled variables.",
  journal  = "American journal of epidemiology",
  volume   =  171,
  number   =  5,
  pages    = "624--632",
  month    =  "1~" # mar,
  year     =  2010,
  url      = "http://www.ncbi.nlm.nih.gov/pubmed/20106935",
  keywords = "Computer Simulation; Data Interpretation, Statistical;
              Epidemiologic Methods; Multivariate Analysis",
  issn     = "0002-9262, 1476-6256",
  pmid     = "20106935",
  doi      = "10.1093/aje/kwp425"
}

@ARTICLE{White2011-gt,
  title    = "{Multiple imputation using chained equations: Issues and guidance
              for practice}",
  author   = "White, Ian R and Royston, Patrick and Wood, Angela M",
  abstract = "Multiple imputation by chained equations is a flexible and
              practical approach to handling missing data. We describe the
              principles of the method and show how to impute categorical and
              quantitative variables, including skewed variables. We give
              guidance on how to specify the imputation model and how many
              imputations are needed. We describe the practical analysis of
              multiply imputed data, including model building and model
              checking. We stress the limitations of the method and discuss the
              possible pitfalls. We illustrate the ideas using a data set in
              mental health, giving Stata code fragments.",
  journal  = "Statistics in medicine",
  volume   =  30,
  number   =  4,
  pages    = "377--399",
  month    =  "20~" # mar,
  year     =  2011,
  url      = "http://www.ncbi.nlm.nih.gov/pubmed/21225900",
  keywords = "Adolescent; Adult; Aged; Cardiovascular Diseases; Cardiovascular
              Diseases: epidemiology; Cholesterol; Cholesterol: blood; Female;
              Humans; Lipoproteins, HDL; Lipoproteins, HDL: blood; Mental
              Health; Mental Health: statistics \& numerical data; Middle Aged;
              Models, Statistical; Multicenter Studies as Topic; Young Adult",
  issn     = "0277-6715, 1097-0258",
  pmid     = "21225900",
  doi      = "10.1002/sim.4067"
}

@ARTICLE{Shah2014-za,
  title    = "{Comparison of random forest and parametric imputation models for
              imputing missing data using MICE: a CALIBER study}",
  author   = "Shah, Anoop D and Bartlett, Jonathan W and Carpenter, James and
              Nicholas, Owen and Hemingway, Harry",
  abstract = "Multivariate imputation by chained equations (MICE) is commonly
              used for imputing missing data in epidemiologic research. The
              ``true'' imputation model may contain nonlinearities which are
              not included in default imputation models. Random forest
              imputation is a machine learning technique which can accommodate
              nonlinearities and interactions and does not require a particular
              regression model to be specified. We compared parametric MICE
              with a random forest-based MICE algorithm in 2 simulation
              studies. The first study used 1,000 random samples of 2,000
              persons drawn from the 10,128 stable angina patients in the
              CALIBER database (Cardiovascular Disease Research using Linked
              Bespoke Studies and Electronic Records; 2001-2010) with complete
              data on all covariates. Variables were artificially made
              ``missing at random,'' and the bias and efficiency of parameter
              estimates obtained using different imputation methods were
              compared. Both MICE methods produced unbiased estimates of (log)
              hazard ratios, but random forest was more efficient and produced
              narrower confidence intervals. The second study used simulated
              data in which the partially observed variable depended on the
              fully observed variables in a nonlinear way. Parameter estimates
              were less biased using random forest MICE, and confidence
              interval coverage was better. This suggests that random forest
              imputation may be useful for imputing complex epidemiologic data
              sets in which some patients have missing data.",
  journal  = "American journal of epidemiology",
  volume   =  179,
  number   =  6,
  pages    = "764--774",
  month    =  "15~" # mar,
  year     =  2014,
  url      = "http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3939843&tool=pmcentrez&rendertype=abstract",
  keywords = "Age Factors; Angina, Stable; Angina, Stable: epidemiology;
              Artificial Intelligence; Bias (Epidemiology); Computer
              Simulation; Confidence Intervals; Epidemiologic Methods; Health
              Behavior; Health Status; Humans; Proportional Hazards Models;
              Random Allocation; Sex Factors",
  issn     = "0002-9262, 1476-6256",
  pmid     = "24589914",
  doi      = "10.1093/aje/kwt312"
}

@ARTICLE{Doove2014-ty,
  title     = "{Recursive partitioning for missing data imputation in the
               presence of interaction effects}",
  author    = "Doove, L L and Van Buuren, S and Dusseldorp, E",
  journal   = "Computational statistics \& data analysis",
  publisher = "Elsevier B.V.",
  volume    =  72,
  pages     = "92--104",
  month     =  apr,
  year      =  2014,
  url       = "http://linkinghub.elsevier.com/retrieve/pii/S0167947313003939",
  issn      = "0167-9473",
  doi       = "10.1016/j.csda.2013.10.025"
}

@MANUAL{R_Core_Team2017-zb,
  title        = "{R: A Language and Environment for Statistical Computing}",
  author       = "{R Core Team}",
  year         =  2017,
  url          = "http://www.r-project.org/",
  address      = "Vienna, Austria",
  organization = "R Foundation for Statistical Computing"
}
